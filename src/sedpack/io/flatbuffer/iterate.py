# Copyright 2024 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
"""Iterate a FlatBuffers shard. See src/sedpack/io/flatbuffer/shard.fbs
sedpack.io.shard.shard_writer_flatbuffer.ShardWriterFlatBuffer for more
information how it is saved.
"""

from pathlib import Path
from typing import Iterable

import aiofiles
import numpy as np

from sedpack.io.compress import CompressedFile
from sedpack.io.metadata import Attribute
from sedpack.io.types import ExampleT
from sedpack.io.shard import IterateShardBase
from sedpack.io.shard.iterate_shard_base import T
from sedpack.io.utils import func_or_identity

# Autogenerated from src/sedpack/io/flatbuffer/shard.fbs
import sedpack.io.flatbuffer.shardfile.Example as fbapi_Example
import sedpack.io.flatbuffer.shardfile.Shard as fbapi_Shard


class IterateShardFlatBuffer(IterateShardBase[T]):
    """Remember everything to be able to iterate shards. This can be pickled
    and passed as a callable object into another process.
    """

    def _iterate_content(self, content: bytes) -> Iterable[ExampleT]:
        shard = fbapi_Shard.Shard.GetRootAs(content, 0)

        for example_id in range(shard.ExamplesLength()):
            example: fbapi_Example.Example = shard.Examples(example_id)

            example_dictionary: ExampleT = {}

            for attribute_id, attribute in enumerate(
                    self.dataset_structure.saved_data_description):
                # No-copy fast retrieval, represented as bytes.
                # This is a manually written method which uses the fact
                # that we know what dtype to decode. It might be cleaner to do
                # this using a union. There are two caveats:
                # - FlatBuffers only support a subset of types we care about
                #   (e.g., float16 which is not included in
                #   flatbuffers/python/flatbuffers/number_types.py).
                # - Speed, since we first need to check the type for every
                #   attribute.
                # Bytearray representation. Little endian, just loaded.
                np_bytes = example.Attributes(
                    attribute_id).AttributeBytesAsNumpy()

                np_array = IterateShardFlatBuffer.decode_array(
                    np_bytes=np_bytes,
                    attribute=attribute,
                )

                # Copy otherwise the arrays are immutable and keep the whole
                # file content from being garbage collected.
                np_array = np.copy(np_array)

                example_dictionary[attribute.name] = np_array

            yield example_dictionary

    @staticmethod
    def decode_array(np_bytes: np.ndarray,
                     attribute: Attribute,
                     batch_size: int = 0) -> np.ndarray:
        """Decode an array. See `sedpack.io.shard.shard_writer_flatbuffer
        .ShardWriterFlatBuffer.save_numpy_vector_as_bytearray`
        for format description. The code tries to avoid unnecessary copies.

        Args:

          np_bytes (np.ndarray): The bytes as an np.array of bytes.

          attribute (Attribute): Description of the final array (dtype and
          shape).

          batch_size (int): If `batch_size` is larger than zero we received a
          batch of these attributes. In case when `batch_size == -1` the
          `np.reshape` auto-deduces the dimension. Otherwise we received
          exactly one value of this attribute.

        Returns: the parsed np.ndarray of the correct dtype and shape.
        """
        dt = np.dtype(attribute.dtype)
        # FlatBuffers are little-endian. There is no byteswap by
        # `np.frombuffer` but the array will be interpreted correctly.
        dt = dt.newbyteorder("<")
        np_array = np.frombuffer(
            buffer=np_bytes,  # a view into the buffer, not a copy
            dtype=dt,
        )

        # Reshape if needed.
        if batch_size > 0 or batch_size == -1:
            np_array = np_array.reshape((batch_size, *attribute.shape))
        else:
            np_array = np_array.reshape(attribute.shape)

        return np_array

    def iterate_shard(self, file_path: Path) -> Iterable[ExampleT]:
        """Iterate a shard.
        """
        # Read then decompress (nice for benchmarking).
        with open(file_path, "rb") as f:
            content = f.read()
        content = CompressedFile(
            self.dataset_structure.compression).decompress(content)
        yield from self._iterate_content(content=content)

    async def iterate_shard_async(self, file_path: Path):
        """Asynchronously iterate a shard.
        """
        async with aiofiles.open(file_path, "rb") as f:
            content = await f.read()
            content = CompressedFile(
                self.dataset_structure.compression).decompress(content)

        for example in self._iterate_content(content=content):
            yield example

    def process_and_list(self, shard_file: Path) -> list[T]:
        """Return a list of processed examples. Used as a function call in a
        different process. Returning a list as opposed to an iterator allows to
        do all work in another process and all that needs to be done is a
        memory copy between processes.

        TODO think of a way to avoid copying memory between processes.

        Args:

            shard_file (Path): Path to the shard file.
        """
        process_record = func_or_identity(self.process_record)

        return [
            process_record(example)
            for example in self.iterate_shard(shard_file)
        ]
